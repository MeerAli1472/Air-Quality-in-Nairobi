{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8321ae5",
   "metadata": {},
   "source": [
    "# Auto Regressive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pymongo import MongoClient\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.ar_model import AutoReg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca6cb5",
   "metadata": {},
   "source": [
    "# 1. Prepare Data\n",
    "## 1.1. Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17d9b0",
   "metadata": {},
   "source": [
    "<b>Task 3.3.1: Complete to the create a client to connect to the MongoDB server, assigns the \"air-quality\" database to db, and assigned the \"nairobi\" connection to nairobi.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host=\"localhost\",port=27017)\n",
    "db = client[\"air_quality\"]\n",
    "nairobi = db[\"nairobi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c8c42",
   "metadata": {},
   "source": [
    "<b>Task 3.3.2: Change the wrangle function below so that it returns a Series of the resampled data instead of a DataFrame.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(collection):\n",
    "    results = collection.find(\n",
    "        {\"metadata.site\": 29, \"metadata.measurement\": \"P2\"},\n",
    "        projection={\"P2\": 1, \"timestamp\": 1, \"_id\": 0},\n",
    "    )\n",
    "\n",
    "    # Read data into DataFrame\n",
    "    df = pd.DataFrame(list(results)).set_index(\"timestamp\")\n",
    "\n",
    "    # Localize timezone\n",
    "    df.index = df.index.tz_localize(\"UTC\").tz_convert(\"Africa/Nairobi\")\n",
    "\n",
    "    # Remove outliers\n",
    "    df = df[df[\"P2\"] < 500]\n",
    "\n",
    "    # Resample to 1hr window\n",
    "    y = df[\"P2\"].resample(\"1H\").mean().fillna(method='ffill').to_frame()\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e21b0",
   "metadata": {},
   "source": [
    "<b>Task 3.3.3: Use your wrangle function to read the data from the nairobi collection into the Series y.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d934c6",
   "metadata": {},
   "source": [
    "# 1.2. Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef35ceb",
   "metadata": {},
   "source": [
    "#  ACF Plot\n",
    "When we've worked with autocorrelations in the past, we've treated them like static relationships, but that's not always how they work. Sometimes, we want to actually see how those autocorrelations change over time, which means we need to think of them as functions. When we create a visual representation of an autocorrelation function (ACF), we're making an ACF plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e60c9ef",
   "metadata": {},
   "source": [
    "<b>Task 3.3.4: Create an ACF plot for the data in y. Be sure to label the x-axis as \"Lag [hours]\" and the y-axis as \"Correlation Coefficient\".</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_acf(y,ax=ax)\n",
    "\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d0dc0",
   "metadata": {},
   "source": [
    "<b>Task 3.3.5: Create an PACF plot for the data in y. Be sure to label the x-axis as \"Lag [hours]\" and the y-axis as \"Correlation Coefficient\".</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28b57ab",
   "metadata": {},
   "source": [
    "# PACF Plot\n",
    "Autocorrelations take into account two types of observations. Direct observations are the ones that happen exactly at our chosen time-step interval; we might have readings at one-hour intervals starting at 1:00. Indirect observations are the ones that happen between our chosen time-step intervals, at time-steps like 1:38, 2:10, 3:04, etc. Those indirect observations might be helpful, but we can't be sure about that, so it's a good idea to strip them out and see what our graph looks like when it's only showing us direct observations.\n",
    "\n",
    "An autocorrelation that only includes the direct observations is called a partial autocorrelation, and when we view that partial autocorrelation as a function, we call it a PACF.\n",
    "\n",
    "PACF plots represent those things visually. We want to compare our ACF and PACF plots to see which model best describes our time series. If the ACF data drops off slowly, then that's going to be a better description; if the PACF falls off slowly, then that's going to be a better description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shift(1).corr(y.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be07470",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plot_pacf(y,ax=ax)\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5051d0",
   "metadata": {},
   "source": [
    "# 1.3. Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dab598",
   "metadata": {},
   "source": [
    "<b>Task 3.3.6: Split y into training and test sets. The first 95% of the data should be in your training set. The remaining 5% should be in the test set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_test = int(len(y) * 0.95)\n",
    "\n",
    "y_train = y.iloc[:cutoff_test]\n",
    "y_test = y.iloc[cutoff_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102fc41a",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "## Baseline\n",
    "<b>Task 3.3.7: Calculate the baseline mean absolute error for your model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece40a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mean = y_train.mean()\n",
    "y_pred_baseline = [y_train_mean] * len(y_train)\n",
    "mae_baseline = mean_absolute_error(y_train, y_pred_baseline)\n",
    "\n",
    "print(\"Mean P2 Reading:\", round(y_train_mean, 2))\n",
    "print(\"Baseline MAE:\", round(mae_baseline, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d7b8d",
   "metadata": {},
   "source": [
    "# Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874bf53",
   "metadata": {},
   "source": [
    "<b>Task 3.3.8: Instantiate an AutoReg model and fit it to the training data y_train. Be sure to set the lags argument to 26</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a521e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoReg(y_train, lags=26).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5efc5b",
   "metadata": {},
   "source": [
    "<b>Task 3.3.9: Generate a list of training predictions for your model and use them to calculate your training mean absolute error.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict().dropna()\n",
    "training_mae = mean_absolute_error(y_train.iloc[26:],y_pred)\n",
    "print(\"Training MAE:\", training_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec601f9",
   "metadata": {},
   "source": [
    "<b>Task 3.3.10: Use y_train and y_pred to calculate the residuals for your model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resid = y_train-y_pred\n",
    "y_train_resid.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ecc1f0",
   "metadata": {},
   "source": [
    "<b>Task 3.3.11: Create a plot of y_train_resid.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48445ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "y_train_resid.plot(ylabel=\"Residual Value\",ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f934dc",
   "metadata": {},
   "source": [
    "<b>Task 3.3.12: Create a histogram of y_train_resid.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ad999",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "y_train_resid.plot(kind=\"hist\",ax=ax);\n",
    "plt.ylabel(\"Residual Value\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.title(\"AR(26) Distribution of Residual\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c4d98",
   "metadata": {},
   "source": [
    "<b>Task 3.3.13: Create an ACF plot of y_train_resid.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a128c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))   #have no more power of prediction\n",
    "plot_acf(y_train_resid, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c562259",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77123900",
   "metadata": {},
   "source": [
    "<b>Task 3.3.14: Calculate the test mean absolute error for your model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(y_test.index.min(), y_test.index.max())\n",
    "test_mae = mean_absolute_error(y_test,y_pred_test)\n",
    "print(\"Test MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38cd88",
   "metadata": {},
   "source": [
    "<b>Task 3.3.15: Create a DataFrame test_predictions that has two columns: \"y_test\" and \"y_pred\". The first should contain the true values for your test set, and the second should contain your model's predictions. Be sure the index of test_predictions matches the index of y_test.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1371b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame(\n",
    "    {\"y_test\": y_test, \"y_pred\": y_pred_test}, index=y_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e840d96",
   "metadata": {},
   "source": [
    "</b>Task 3.3.16: Create a time series plot for the values in test_predictions using plotly express. Be sure that the y-axis is properly labeled as \"P2\".<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_pred_test, labels={\"value\": \"P2\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda70ab",
   "metadata": {},
   "source": [
    "<b>Task 3.3.17: Perform walk-forward validation for your model for the entire test set y_test. Store your model's predictions in the Series y_pred_wfv.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048e896",
   "metadata": {},
   "source": [
    "# Walk-Forward Validation\n",
    "Our predictions lose power over time because the model gets farther and farther away from its beginning. But what if we could move that beginning forward with the model? That's what walk-forward validation is. In a walk-forward validation, we re-train the model at for each new observation in the dataset, dropping the data that's the farthest in the past. Let's say that our prediction for what's going to happen at 12:00 is based on what happened at 11:00, 10:00, and 9:00. When we move forward an hour to predict what's going to happen at 1:00, we only use data from 10:00, 11:00, and 12:00, dropping the data from 9:00 because it's now too far in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e06eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "y_pred_wfv = pd.Series()\n",
    "history = y_train.copy()\n",
    "for i in range(len(y_test)):\n",
    "    model = AutoReg(history, lags=26).fit()\n",
    "    next_pred = model.forecast()\n",
    "    y_pred_wfv = y_pred_wfv.append(next_pred)\n",
    "    histroy = history.append(y_test[next_pred.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d239b4",
   "metadata": {},
   "source": [
    "<b>Task 3.3.18: Calculate the test mean absolute error for your model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2dd1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = mean_absolute_error(y_test ,y_pred_wfv)\n",
    "print(\"Test MAE (walk forward validation):\", round(test_mae, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744092e1",
   "metadata": {},
   "source": [
    "<b>Task 3.3.19: Print out the parameters for your trained model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5036ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14911898",
   "metadata": {},
   "source": [
    "<b>Task 3.3.20: Put the values for y_test and y_pred_wfv into the DataFrame df_pred_test (don't forget the index). Then plot df_pred_test using plotly express.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4677ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame(\n",
    "    {\"y_test\":y_test, \"y_pred_wfv\": y_pred_wfv}\n",
    ")\n",
    "fig = px.line(df_pred_test, labels={\"value\":\"PM2.5\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c5db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
